{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "674d71bd",
   "metadata": {},
   "source": [
    "# Proposta de monitoramento do site Reddit\n",
    "\n",
    "### O Reddit é um agregador social de notícias ou um social bookmarks. O Reddit é dividido em várias comunidades chamadas de \"subreddits\". São nesses subreddits que reside o conteúdo do site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b00a95db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c98aca",
   "metadata": {},
   "source": [
    "## Função que extrai os dados e retorna uma lista com diversos dicionários\n",
    "\n",
    "### Na função abaixo é recebido o html da página do subreddit, procurando a tag 'main' com todos os 'articles' (que contém o conteúdo de cada post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbd2229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para extrair o título, autor, link e tag dos posts\n",
    "def extrair_reddit_posts(subreddit: str) -> list:\n",
    "    infos_list = []\n",
    "    soup = BeautifulSoup(subreddit, 'html5lib')\n",
    "        \n",
    "    # Encontrando os artigos\n",
    "    articles = soup.find('main', id='main-content').find_all('article')\n",
    "        \n",
    "    for article in articles:\n",
    "        infos = {}\n",
    "        infos['Author'] = article.find('shreddit-post').get('author')\n",
    "        infos['Title'] = article.find('shreddit-post').get('post-title').strip()\n",
    "        infos['Link'] = f\"reddit.com{article.find('shreddit-post').get('permalink')}\"\n",
    "        infos['Upvotes'] = article.find('shreddit-post').get('score')\n",
    "        infos['Comments'] = article.find('shreddit-post').get('comment-count')\n",
    "        infos['Post-type'] = article.find('shreddit-post').get('post-type')\n",
    "        infos['Date'] = datetime.strptime(article.find('time').get('datetime'), \"%Y-%m-%dT%H:%M:%S.%fZ\").date()\n",
    "        try:\n",
    "            infos['Tag'] = article.find('a', class_='no-decoration').find('div').text.strip()\n",
    "        except AttributeError:\n",
    "            infos['Tag'] = None\n",
    "        infos_list.append(infos)\n",
    "\n",
    "    return infos_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533dd211",
   "metadata": {},
   "source": [
    "## A função abaixo cria uma tabela em uma database sqlite com o nome do subreddit digitado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09c7bd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sql_table(subreddit: str) -> None:\n",
    "    # Conectar ao banco de dados (se não existir, será criado)\n",
    "    conexao = sqlite3.connect(f'{subreddit}.db')\n",
    "    cursor = conexao.cursor()\n",
    "\n",
    "    # Criar tabela (se ainda não existir)\n",
    "    cursor.execute('''CREATE TABLE IF NOT EXISTS subreddits (\n",
    "                        ID INTEGER PRIMARY KEY,\n",
    "                        TÍTULO TEXT,\n",
    "                        AUTOR TEXT,\n",
    "                        LINK TEXT,\n",
    "                        TAG TEXT,\n",
    "                        UPVOTES INTEGER,\n",
    "                        COMENTÁRIOS INTEGER,\n",
    "                        POST_TYPE TEXT,\n",
    "                        DATA DATE\n",
    "                    )''')\n",
    "    \n",
    "    # Confirmar a transação\n",
    "    conexao.commit()\n",
    "\n",
    "    # Fechar conexão\n",
    "    conexao.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98375470",
   "metadata": {},
   "source": [
    "## Após criar a tabela na função acima, a função abaixo salva os dados na db\n",
    "### A função é iniciada com 2 argumentos, o dicionário da primeira função, contendo detalhes do post, e o subreddit para acessar a tabela na conexão com a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a65200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_in_sqlite(content: dict, subreddit: str) -> None:\n",
    "    # Conectando ao banco de dados\n",
    "    conexao = sqlite3.connect(f'{subreddit}.db')\n",
    "    cursor = conexao.cursor()\n",
    "    \n",
    "    # Conferindo se o post já existe\n",
    "    cursor.execute('''SELECT LINK FROM subreddits WHERE LINK = ?''', (content['Link'],))\n",
    "    existing_content = cursor.fetchone()\n",
    "    \n",
    "    if not existing_content:\n",
    "        # Inserir dados do dicionário na tabela\n",
    "        cursor.execute('''INSERT INTO subreddits (TÍTULO, AUTOR, LINK, TAG, UPVOTES, COMENTÁRIOS, POST_TYPE, DATA)\n",
    "                          VALUES (?, ?, ?, ?, ?, ?, ?, ?)''', (content['Title'], content['Author'], content['Link'], content['Tag'], content['Upvotes'], content['Comments'], content['Post-type'], content['Date']))\n",
    "\n",
    "        # Confirmar a transação\n",
    "        conexao.commit()\n",
    "\n",
    "    # Fechar conexão\n",
    "    conexao.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edc59003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para rolar até o final da página e carregar mais posts\n",
    "def scroll_to_bottom(driver) -> None:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc128172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digite o subreddit desejado: datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The chromedriver version (123.0.6312.105) detected in PATH at C:\\Users\\Loguera\\Desktop\\chromedriver-win64\\chromedriver.exe might not be compatible with the detected chrome version (124.0.6367.63); currently, chromedriver 124.0.6367.91 is recommended for chrome 124.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    }
   ],
   "source": [
    "sub_reddit = input(\"Digite o subreddit desejado: \")\n",
    "\n",
    "url = f'https://www.reddit.com/r/{sub_reddit}/'\n",
    "\n",
    "# Inicializando o driver do Selenium\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Abrindo o URL\n",
    "driver.get(url)\n",
    "\n",
    "# Encontrando o botão de login e cliquando nele\n",
    "login_button = driver.find_element(By.ID, \"login-button\")\n",
    "login_button.click()\n",
    "\n",
    "# Aguardando um pouco para que a página de login seja carregada completamente\n",
    "time.sleep(2)\n",
    "\n",
    "# Encontrando os campos para input de usuário e senha\n",
    "username_field = driver.find_element(By.ID, \"login-username\")\n",
    "password_field = driver.find_element(By.ID, \"login-password\")\n",
    "\n",
    "# Inserindo usúario e senha (*LEMBRAR DE NÃO DEIXA VISÍVEL NA HORA DE APRESENTAR*)\n",
    "username_field.send_keys(\"loguera\")\n",
    "password_field.send_keys(\"Fontenova231\")\n",
    "\n",
    "# Enviando as credenciais (pressionando enter no campo de senha)\n",
    "password_field.send_keys(Keys.RETURN)\n",
    "\n",
    "# Esperando um pouco para o poput de login e senha sair\n",
    "time.sleep(2)\n",
    "\n",
    "# Rolando até o final da página, 120 vezes, oara carregar mais posts\n",
    "for _ in range(120):\n",
    "    scroll_to_bottom(driver)\n",
    "    time.sleep(2)\n",
    "\n",
    "# Extraindo posts da página inicial\n",
    "html_content = driver.page_source\n",
    "# Variável com a função que extrairá posts\n",
    "posts = extrair_reddit_posts(html_content)\n",
    "# Chamando função que cria a tabela na db\n",
    "create_sql_table(sub_reddit)\n",
    "\n",
    "for post in posts:\n",
    "    # Salvando cada dicionário da lista na db\n",
    "    save_in_sqlite(post, sub_reddit)\n",
    "    \n",
    "# Encerrando o driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ecd5b770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar ao banco de dados\n",
    "conexao = sqlite3.connect(f'{sub_reddit}.db')\n",
    "\n",
    "# Executar consultas\n",
    "query = \"SELECT * FROM subreddits\"\n",
    "df = pd.read_sql_query(query, conexao, index_col='ID')\n",
    "\n",
    "# Fechar a conexão\n",
    "conexao.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3baf3af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões originais:  (1000, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensões originais: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0f0b6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TÍTULO', 'AUTOR', 'LINK', 'TAG', 'UPVOTES', 'COMENTÁRIOS', 'POST_TYPE',\n",
       "       'DATA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d35a805e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TÍTULO         object\n",
       "AUTOR          object\n",
       "LINK           object\n",
       "TAG            object\n",
       "UPVOTES         int64\n",
       "COMENTÁRIOS     int64\n",
       "POST_TYPE      object\n",
       "DATA           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e31967f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TÍTULO         0\n",
       "AUTOR          0\n",
       "LINK           0\n",
       "TAG            2\n",
       "UPVOTES        0\n",
       "COMENTÁRIOS    0\n",
       "POST_TYPE      0\n",
       "DATA           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85730408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TÍTULO</th>\n",
       "      <th>AUTOR</th>\n",
       "      <th>LINK</th>\n",
       "      <th>TAG</th>\n",
       "      <th>UPVOTES</th>\n",
       "      <th>COMENTÁRIOS</th>\n",
       "      <th>POST_TYPE</th>\n",
       "      <th>DATA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Large Language Models for Data Annotation: A S...</td>\n",
       "      <td>cavedave</td>\n",
       "      <td>reddit.com/r/datasets/comments/1ax75og/large_l...</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>link</td>\n",
       "      <td>2024-02-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>Bible datasets</td>\n",
       "      <td>cavedave</td>\n",
       "      <td>reddit.com/r/datasets/comments/17pfhgy/bible_d...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>link</td>\n",
       "      <td>2023-11-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TÍTULO     AUTOR  \\\n",
       "ID                                                                 \n",
       "303  Large Language Models for Data Annotation: A S...  cavedave   \n",
       "744                                     Bible datasets  cavedave   \n",
       "\n",
       "                                                  LINK   TAG  UPVOTES  \\\n",
       "ID                                                                      \n",
       "303  reddit.com/r/datasets/comments/1ax75og/large_l...  None        3   \n",
       "744  reddit.com/r/datasets/comments/17pfhgy/bible_d...  None        2   \n",
       "\n",
       "     COMENTÁRIOS POST_TYPE        DATA  \n",
       "ID                                      \n",
       "303            4      link  2024-02-22  \n",
       "744            0      link  2023-11-06  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "979b90a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TÍTULO</th>\n",
       "      <th>AUTOR</th>\n",
       "      <th>LINK</th>\n",
       "      <th>TAG</th>\n",
       "      <th>UPVOTES</th>\n",
       "      <th>COMENTÁRIOS</th>\n",
       "      <th>POST_TYPE</th>\n",
       "      <th>DATA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Why use R instead of Python for data stuff?</td>\n",
       "      <td>Nickaroo321</td>\n",
       "      <td>reddit.com/r/datasets/comments/1bo6b2s/why_use...</td>\n",
       "      <td>question</td>\n",
       "      <td>93</td>\n",
       "      <td>77</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>I made OMDB, the world's largest downloadable ...</td>\n",
       "      <td>OatsCG</td>\n",
       "      <td>reddit.com/r/datasets/comments/1b9ihqa/i_made_...</td>\n",
       "      <td>dataset</td>\n",
       "      <td>73</td>\n",
       "      <td>13</td>\n",
       "      <td>link</td>\n",
       "      <td>2024-03-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Dateno - a new dataset search engine</td>\n",
       "      <td>ivan-begtin</td>\n",
       "      <td>reddit.com/r/datasets/comments/1bdn4om/dateno_...</td>\n",
       "      <td>request</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>I built a free tool that auto-generates scrape...</td>\n",
       "      <td>madredditscientist</td>\n",
       "      <td>reddit.com/r/datasets/comments/16nq9n6/i_built...</td>\n",
       "      <td>resource</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>multi_media</td>\n",
       "      <td>2023-09-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1-Year of Life Data. What makes me happy?</td>\n",
       "      <td>tsawsum1</td>\n",
       "      <td>reddit.com/r/datasets/comments/1bnjzk5/1year_o...</td>\n",
       "      <td>dataset</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>multi_media</td>\n",
       "      <td>2024-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>Does anybody have access to a dataset of black...</td>\n",
       "      <td>The-White-Furry</td>\n",
       "      <td>reddit.com/r/datasets/comments/1ajpekn/does_an...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>Crypto currency datasets required for performi...</td>\n",
       "      <td>Varc20</td>\n",
       "      <td>reddit.com/r/datasets/comments/17e6kuu/crypto_...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>text</td>\n",
       "      <td>2023-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>Looking for a political compass questionnaire ...</td>\n",
       "      <td>Play4u</td>\n",
       "      <td>reddit.com/r/datasets/comments/1ak4x78/looking...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-02-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Exploring the spread of pro-Israel and pro-Pal...</td>\n",
       "      <td>cavedave</td>\n",
       "      <td>reddit.com/r/datasets/comments/1akgkbk/explori...</td>\n",
       "      <td>dataset</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>link</td>\n",
       "      <td>2024-02-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>Looking for Malaysia socio economic, demograph...</td>\n",
       "      <td>LYJ9339</td>\n",
       "      <td>reddit.com/r/datasets/comments/192c18a/looking...</td>\n",
       "      <td>request</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-01-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TÍTULO               AUTOR  \\\n",
       "ID                                                                           \n",
       "148        Why use R instead of Python for data stuff?         Nickaroo321   \n",
       "231  I made OMDB, the world's largest downloadable ...              OatsCG   \n",
       "207               Dateno - a new dataset search engine         ivan-begtin   \n",
       "947  I built a free tool that auto-generates scrape...  madredditscientist   \n",
       "155          1-Year of Life Data. What makes me happy?            tsawsum1   \n",
       "..                                                 ...                 ...   \n",
       "371  Does anybody have access to a dataset of black...     The-White-Furry   \n",
       "811  Crypto currency datasets required for performi...              Varc20   \n",
       "369  Looking for a political compass questionnaire ...              Play4u   \n",
       "367  Exploring the spread of pro-Israel and pro-Pal...            cavedave   \n",
       "501  Looking for Malaysia socio economic, demograph...             LYJ9339   \n",
       "\n",
       "                                                  LINK       TAG  UPVOTES  \\\n",
       "ID                                                                          \n",
       "148  reddit.com/r/datasets/comments/1bo6b2s/why_use...  question       93   \n",
       "231  reddit.com/r/datasets/comments/1b9ihqa/i_made_...   dataset       73   \n",
       "207  reddit.com/r/datasets/comments/1bdn4om/dateno_...   request       46   \n",
       "947  reddit.com/r/datasets/comments/16nq9n6/i_built...  resource       33   \n",
       "155  reddit.com/r/datasets/comments/1bnjzk5/1year_o...   dataset       29   \n",
       "..                                                 ...       ...      ...   \n",
       "371  reddit.com/r/datasets/comments/1ajpekn/does_an...   request        0   \n",
       "811  reddit.com/r/datasets/comments/17e6kuu/crypto_...   request        0   \n",
       "369  reddit.com/r/datasets/comments/1ak4x78/looking...   request        0   \n",
       "367  reddit.com/r/datasets/comments/1akgkbk/explori...   dataset        0   \n",
       "501  reddit.com/r/datasets/comments/192c18a/looking...   request        0   \n",
       "\n",
       "     COMENTÁRIOS    POST_TYPE        DATA  \n",
       "ID                                         \n",
       "148           77         text  2024-03-26  \n",
       "231           13         link  2024-03-08  \n",
       "207           13         text  2024-03-13  \n",
       "947            9  multi_media  2023-09-20  \n",
       "155            6  multi_media  2024-03-25  \n",
       "..           ...          ...         ...  \n",
       "371            4         text  2024-02-05  \n",
       "811            4         text  2023-10-22  \n",
       "369            0         text  2024-02-06  \n",
       "367            2         link  2024-02-06  \n",
       "501            1         text  2024-01-09  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='UPVOTES', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f1452e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TÍTULO</th>\n",
       "      <th>AUTOR</th>\n",
       "      <th>LINK</th>\n",
       "      <th>TAG</th>\n",
       "      <th>UPVOTES</th>\n",
       "      <th>COMENTÁRIOS</th>\n",
       "      <th>POST_TYPE</th>\n",
       "      <th>DATA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>[P] How I found 8 bugs in Google's Gemma 6T to...</td>\n",
       "      <td>danielhanchen</td>\n",
       "      <td>reddit.com/r/MachineLearning/comments/1bipsqj/...</td>\n",
       "      <td>Project</td>\n",
       "      <td>469</td>\n",
       "      <td>59</td>\n",
       "      <td>multi_media</td>\n",
       "      <td>2024-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>[P] Paperlib: An open-source and modern-design...</td>\n",
       "      <td>GeoffreyChen</td>\n",
       "      <td>reddit.com/r/MachineLearning/comments/1bh63c1/...</td>\n",
       "      <td>Project</td>\n",
       "      <td>200</td>\n",
       "      <td>89</td>\n",
       "      <td>multi_media</td>\n",
       "      <td>2024-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>[P] SWE-agent: an open source coding agent tha...</td>\n",
       "      <td>ofirpress</td>\n",
       "      <td>reddit.com/r/MachineLearning/comments/1btwl37/...</td>\n",
       "      <td>Project</td>\n",
       "      <td>170</td>\n",
       "      <td>21</td>\n",
       "      <td>multi_media</td>\n",
       "      <td>2024-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>[P] Using ML to Annotate Dental Xrays</td>\n",
       "      <td>Responsible-Win3865</td>\n",
       "      <td>reddit.com/r/MachineLearning/comments/1brbaii/...</td>\n",
       "      <td>Project</td>\n",
       "      <td>133</td>\n",
       "      <td>23</td>\n",
       "      <td>image</td>\n",
       "      <td>2024-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>[P] Jamba: the first production-grade Mamba-ba...</td>\n",
       "      <td>ghosthamlet</td>\n",
       "      <td>reddit.com/r/MachineLearning/comments/1bqfibp/...</td>\n",
       "      <td>Project</td>\n",
       "      <td>131</td>\n",
       "      <td>18</td>\n",
       "      <td>multi_media</td>\n",
       "      <td>2024-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>[Project] I need to create a Raster image to V...</td>\n",
       "      <td>GodMan6660</td>\n",
       "      <td>reddit.com/r/MachineLearning/comments/1bqmy0l/...</td>\n",
       "      <td>Project</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>Code base documentation and testing using LLM [P]</td>\n",
       "      <td>Soaccer</td>\n",
       "      <td>reddit.com/r/MachineLearning/comments/1bqdkge/...</td>\n",
       "      <td>Project</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>multi_media</td>\n",
       "      <td>2024-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>[P]I turned Elon Musk's face into a decision b...</td>\n",
       "      <td>lildaemon</td>\n",
       "      <td>reddit.com/r/MachineLearning/comments/1bqkcor/...</td>\n",
       "      <td>Project</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>multi_media</td>\n",
       "      <td>2024-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>[Project] AI powered products in stores</td>\n",
       "      <td>Complete-Holiday-610</td>\n",
       "      <td>reddit.com/r/MachineLearning/comments/1c7q6o1/...</td>\n",
       "      <td>Project</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-04-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>[P]: Voice Cloning Question</td>\n",
       "      <td>nictamerr</td>\n",
       "      <td>reddit.com/r/MachineLearning/comments/1bwsbvj/...</td>\n",
       "      <td>Project</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-04-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TÍTULO                 AUTOR  \\\n",
       "ID                                                                             \n",
       "835  [P] How I found 8 bugs in Google's Gemma 6T to...         danielhanchen   \n",
       "894  [P] Paperlib: An open-source and modern-design...          GeoffreyChen   \n",
       "544  [P] SWE-agent: an open source coding agent tha...             ofirpress   \n",
       "617              [P] Using ML to Annotate Dental Xrays   Responsible-Win3865   \n",
       "643  [P] Jamba: the first production-grade Mamba-ba...           ghosthamlet   \n",
       "..                                                 ...                   ...   \n",
       "668  [Project] I need to create a Raster image to V...            GodMan6660   \n",
       "669  Code base documentation and testing using LLM [P]               Soaccer   \n",
       "677  [P]I turned Elon Musk's face into a decision b...             lildaemon   \n",
       "192            [Project] AI powered products in stores  Complete-Holiday-610   \n",
       "498                        [P]: Voice Cloning Question             nictamerr   \n",
       "\n",
       "                                                  LINK      TAG  UPVOTES  \\\n",
       "ID                                                                         \n",
       "835  reddit.com/r/MachineLearning/comments/1bipsqj/...  Project      469   \n",
       "894  reddit.com/r/MachineLearning/comments/1bh63c1/...  Project      200   \n",
       "544  reddit.com/r/MachineLearning/comments/1btwl37/...  Project      170   \n",
       "617  reddit.com/r/MachineLearning/comments/1brbaii/...  Project      133   \n",
       "643  reddit.com/r/MachineLearning/comments/1bqfibp/...  Project      131   \n",
       "..                                                 ...      ...      ...   \n",
       "668  reddit.com/r/MachineLearning/comments/1bqmy0l/...  Project        0   \n",
       "669  reddit.com/r/MachineLearning/comments/1bqdkge/...  Project        0   \n",
       "677  reddit.com/r/MachineLearning/comments/1bqkcor/...  Project        0   \n",
       "192  reddit.com/r/MachineLearning/comments/1c7q6o1/...  Project        0   \n",
       "498  reddit.com/r/MachineLearning/comments/1bwsbvj/...  Project        0   \n",
       "\n",
       "     COMENTÁRIOS    POST_TYPE        DATA  \n",
       "ID                                         \n",
       "835           59  multi_media  2024-03-19  \n",
       "894           89  multi_media  2024-03-17  \n",
       "544           21  multi_media  2024-04-02  \n",
       "617           23        image  2024-03-30  \n",
       "643           18  multi_media  2024-03-29  \n",
       "..           ...          ...         ...  \n",
       "668           19         text  2024-03-29  \n",
       "669            0  multi_media  2024-03-29  \n",
       "677           15  multi_media  2024-03-29  \n",
       "192            2         text  2024-04-19  \n",
       "498            3         text  2024-04-05  \n",
       "\n",
       "[174 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['TAG'] == 'Project'].sort_values(by='UPVOTES', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7041ac8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['reddit.com/r/datasets/comments/1boy114/video_dataset_for_abnormal_event_detection_in/'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.index == 147].LINK.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
